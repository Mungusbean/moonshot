import logging
from typing import Any

from openai import AsyncOpenAI

from moonshot.src.connectors.connector import Connector, perform_retry
from moonshot.src.connectors_endpoints.connector_endpoint_arguments import (
    ConnectorEndpointArguments,
)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class OpenAIGpt35Turbo16k(Connector):
    def __init__(self, ep_arguments: ConnectorEndpointArguments):
        # Initialize super class
        super().__init__(ep_arguments)

        # Set OpenAI Key
        self._client = AsyncOpenAI(api_key=self.token)

    @Connector.rate_limited
    @perform_retry
    async def get_response(self, prompt: str) -> str:
        """
        Fetches and returns a response from the OpenAI GPT-3.5 API based on the provided prompt.

        This method sends a prompt to the OpenAI GPT-3.5 API and returns the generated response.
        It is designed to interact with the API, encapsulating the request and response handling within the
        context of this connector instance.

        Args:
            prompt (str): The input prompt to send to the OpenAI API.

        Returns:
            str: The text response generated by the OpenAI GPT-3.5 model.
        """
        connector_prompt = f"{self.pre_prompt}{prompt}{self.post_prompt}"
        if self.system_prompt:
            openai_request = [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": connector_prompt},
            ]
        else:
            openai_request = [{"role": "user", "content": connector_prompt}]

        # Merge self.optional_params with additional parameters
        new_params = {
            **self.optional_params,
            "model": "gpt-3.5-turbo-16k",
            "messages": openai_request,
            "timeout": self.timeout,
        }
        response = await self._client.chat.completions.create(**new_params)
        return await self._process_response(response)

    async def _process_response(self, response: Any) -> str:
        """
        Processes the OpenAI API's response, extracting and returning the AI-generated text.

        This function is designed to handle the response from an OpenAI API call, focusing on the chat completion
        response format. It extracts the AI-generated text from the first choice in the response, which is
        the direct output based on the input prompt provided.

        Args:
            response (Any): The response object from an OpenAI API call, expected to conform to the chat
            completion response format.

        Returns:
            str: The AI-generated text extracted from the first choice in the response, representing the
            model's output based on the provided prompt.
        """
        return response.choices[0].message.content
