{
    "id": "mmlu",
    "name": "MMLU",
    "description": "To measure model's ability in answering accurately across 57 tasks including elementary mathemathics, US history, computer science, law, and more.",
    "tags": [
    ],
    "categories": [
        "capability"
    ],
    "datasets": [
        "mmlu-all"
    ],
    "prompt_templates": [
        "mmlu"
    ],
    "metrics": [
        "exactstrmatch"
    ],
    "attack_modules": [],
    "grading_scale": {
        "A": [
            0.0,
            0.199999
        ],
        "B": [
            0.2,
            0.399999
        ],
        "C": [
            0.4,
            0.599999
        ],
        "D": [
            0.6,
            0.799999
        ],
        "E": [
            0.8,
            1.0
        ]
    }
}